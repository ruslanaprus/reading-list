# Ollama specific properties
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.1:latest

# Explicitly disable Gemini auto-configuration when ollama profile is active
spring.ai.vertex.ai.gemini.enabled=false

# Explicitly exclude the Gemini auto-configuration class
spring.autoconfigure.exclude=org.springframework.ai.autoconfigure.vertexai.gemini.VertexAiGeminiAutoConfiguration
